{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12720bbd-24bb-4c54-bf12-b125b005a34f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from MatlabFuncs import *\n",
    "from model import *\n",
    "from triangle import *\n",
    "from bamg import bamg\n",
    "from savevars import *\n",
    "import plotdoc\n",
    "from loadmodel import *\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "from export_netCDF import export_netCDF\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from m1qn3inversion import *\n",
    "import numpy as np\n",
    "from ContourToNodes import *\n",
    "from solve import *\n",
    "\n",
    "#import lhsmdu #install in terminal 'pip install lhsmdu'\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from InterpFromGridToMesh import InterpFromGridToMesh\n",
    "from InterpFromMeshToMesh2d import InterpFromMeshToMesh2d\n",
    "\n",
    "import copy\n",
    "import utilities\n",
    "from reinitializelevelset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900b1d69-393b-4256-9007-3a0c02306fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'SAtoES'\n",
    "start_year  = 1985."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-marble",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load a separate model to extract the friction coefficient and rheology\n",
    "md_friction = loadmodel(\"./Models/SAtoES_friction_coefficient.nc\")\n",
    "friction_coefficient = md_friction.results.StressbalanceSolution.FrictionCoefficient\n",
    "rheology_B = md_friction.materials.rheology_B\n",
    "md_friction = None\n",
    "\n",
    "# Load the original model\n",
    "md = loadmodel(\"./Models/SAtoES_inversion.nc\")\n",
    "md.friction.coefficient = friction_coefficient\n",
    "md.materials.rheology_B = rheology_B\n",
    "\n",
    "md.levelset.spclevelset = np.nan * np.ones((md.mesh.numberofvertices))\n",
    "pos = md.mesh.vertexonboundary == 1\n",
    "#pos = np.where(md.mesh.vertexonboundary)\n",
    "md.levelset.spclevelset[pos] = md.mask.ice_levelset[pos]\n",
    "md.levelset.migration_max = 1e10\n",
    "plotmodel(md, 'data', md.mask.ice_levelset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-toronto",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Relaxation\n",
    "relaxation_years = 30 #try 5 years if 1 runs quickly\n",
    "\n",
    "# Special post-processing of inverted friction coefficient\n",
    "filename = 'Exp/' + region + '_coeffront_after_inversion.exp'\n",
    "if os.path.isfile(filename):\n",
    "  print('adjusting inverted friction coefficient at the glacier fronts')\n",
    "  pos = find(ContourToNodes(md.mesh.x, md.mesh.y, filename, 1))\n",
    "  md.friction.coefficient[pos] = 10\n",
    "\n",
    "md.initialization.pressure = np.zeros([md.mesh.numberofvertices,1])\n",
    "md.initialization.temperature = 250*np.ones([md.mesh.numberofvertices,1]) #temperature is in kelvin\n",
    "\n",
    "# Set parameters\n",
    "md.inversion.iscontrol=0;\n",
    "md.timestepping.start_time = start_year;\n",
    "md.timestepping.time_step  = .02;\n",
    "md.timestepping.final_time = start_year + relaxation_years;\n",
    "md.settings.output_frequency = (1/md.timestepping.time_step)/5; # 5/yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define fjord walls/flush where bed > 0 (code added 8/3/22)\n",
    "n_buffer = 2\n",
    "for i in range(n_buffer):\n",
    "    elements = md.mesh.elements.astype(int)-1\n",
    "    nodes_edge = elements[np.where(np.sum(md.mask.ice_levelset[elements] == -1, axis=1) == 2)[0]]\n",
    "    nodes_edge = np.unique(nodes_edge.ravel())\n",
    "    nodes_bed = np.where(md.geometry.bed > 0)[0]\n",
    "    nodes_edge_bed = np.array(list(set(nodes_edge) & set(nodes_bed)))\n",
    "    plt.plot(md.mesh.x[nodes_edge_bed], md.mesh.y[nodes_edge_bed], 'r.', markersize=10)\n",
    "\n",
    "    md.mask.ice_levelset[nodes_edge_bed] = -1\n",
    "    md.geometry.thickness[nodes_edge_bed] = 10\n",
    "    md.geometry.surface[nodes_edge_bed] = md.geometry.bed[nodes_edge_bed] + md.geometry.thickness[nodes_edge_bed]\n",
    "\n",
    "    md.friction.coefficient[nodes_edge_bed] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining thermal and sub. discharge at every ISSM mesh node \n",
    "\n",
    "# load raster of basins\n",
    "ds = gdal.Open('./Cheat_matfiles/tidewaterbasins_rignotid.mat_tidewaterbasins.tif', gdal.GA_ReadOnly)\n",
    "rb = ds.GetRasterBand(1)\n",
    "basins_array = rb.ReadAsArray()\n",
    "\n",
    "gt = ds.GetGeoTransform()\n",
    "ulx, xres, xskew, uly, yskew, yres  = gt\n",
    "lrx = ulx + (ds.RasterXSize * xres)\n",
    "lry = uly + (ds.RasterYSize * yres)\n",
    "x = np.arange(ulx, lrx,  xres)\n",
    "y = np.arange(lry, uly, -yres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate basin to each mesh node \n",
    "px = np.array( ((md.mesh.x - gt[0]) / gt[1]).astype(int) )\n",
    "py = np.array( ((md.mesh.y - gt[3]) / gt[5]).astype(int) )\n",
    "\n",
    "basins_mesh = basins_array[py.astype(int), px.astype(int)]\n",
    "\n",
    "# ISSM wants basins to be numbered from 1 to 4 with the basins that we don't care about numbered 0\n",
    "basins_mesh[basins_mesh==13] = 1\n",
    "basins_mesh[basins_mesh==52] = 2\n",
    "basins_mesh[basins_mesh==53] = 3\n",
    "basins_mesh[basins_mesh==90] = 4\n",
    "basins_mesh[(basins_mesh<1) | (basins_mesh>4)] = 0\n",
    "\n",
    "# find basin id for each element\n",
    "basins_elements = basins_mesh[md.mesh.elements-1]\n",
    "basins_elements = np.max(basins_elements, axis=1)\n",
    "\n",
    "plotmodel(md, 'data', basins_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-wednesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning ocean thermal (EN4) and subglacial discharge (RACMO2.3p2) forcings\n",
    "from scipy_io_utils import *\n",
    "\n",
    "# Load historical forcing data\n",
    "glacier_list = list()\n",
    "m = loadmat('./Cheat_matfiles/glacier0013.mat')\n",
    "glacier0013 = m['glacier0013']\n",
    "m = loadmat('./Cheat_matfiles/glacier0052.mat')\n",
    "glacier0052 = m['glacier0052']\n",
    "m = loadmat('./Cheat_matfiles/glacier0053.mat')\n",
    "glacier0053 = m['glacier0053']\n",
    "m = loadmat('./Cheat_matfiles/glacier0090.mat')\n",
    "glacier0090 = m['glacier0090']\n",
    "\n",
    "# Thermal forcing\n",
    "t = glacier0013['EN4']['t']\n",
    "TF = glacier0013['EN4']['TF']\n",
    "\n",
    "# Discharge\n",
    "t = glacier0013['RACMO']['Q']\n",
    "Q = glacier0013['RACMO']['Q']\n",
    "\n",
    "from frontalforcingsrignot import frontalforcingsrignot\n",
    "md.frontalforcings = frontalforcingsrignot()\n",
    "valid = ~np.isnan(glacier0013['EN4']['TF'])\n",
    "md.frontalforcings.thermalforcing = np.zeros( (md.mesh.numberofvertices+1, len(glacier0013['EN4']['TF'][valid])) )\n",
    "md.frontalforcings.subglacial_discharge = np.zeros( (md.mesh.numberofvertices+1, len(glacier0013['RACMO']['Q'])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign forcings to correct node \n",
    "\n",
    "# step 1: find which nodes belong to each basin using basin_mesh\n",
    "get_indexes = lambda basins_mesh, xs: [i for (y, i) in zip(xs, range(len(xs))) if basins_mesh == y]\n",
    "glacier13_nodes = get_indexes(1,basins_mesh)\n",
    "glacier52_nodes = get_indexes(2,basins_mesh)\n",
    "glacier53_nodes = get_indexes(3,basins_mesh)\n",
    "glacier90_nodes = get_indexes(4,basins_mesh)\n",
    "\n",
    "# NOTE: Denis combined steps 2 and 3: we select the rows and set to the TF time series\n",
    "# step 2: select() rows from frontalforcings.thermal that correspond to step 1 nodes\n",
    "md.frontalforcings.thermalforcing[glacier13_nodes,:] = glacier0013['EN4']['TF'][valid]\n",
    "md.frontalforcings.thermalforcing[glacier52_nodes,:] = glacier0052['EN4']['TF'][valid]\n",
    "md.frontalforcings.thermalforcing[glacier53_nodes,:] = glacier0053['EN4']['TF'][valid]\n",
    "md.frontalforcings.thermalforcing[glacier90_nodes,:] = glacier0090['EN4']['TF'][valid]\n",
    "\n",
    "# step 2: select() rows from frontalforcings.subglacial_discharge that correspond to step 1 nodes\n",
    "md.frontalforcings.subglacial_discharge[glacier13_nodes,:] = glacier0013['RACMO']['Q'] * 86400\n",
    "md.frontalforcings.subglacial_discharge[glacier52_nodes,:] = glacier0052['RACMO']['Q'] * 86400\n",
    "md.frontalforcings.subglacial_discharge[glacier53_nodes,:] = glacier0053['RACMO']['Q'] * 86400\n",
    "md.frontalforcings.subglacial_discharge[glacier90_nodes,:] = glacier0090['RACMO']['Q'] * 86400\n",
    "\n",
    "# NOTE: And now, set the last row to the time\n",
    "md.frontalforcings.thermalforcing[-1,:] = glacier0013['EN4']['t'][valid]\n",
    "md.frontalforcings.subglacial_discharge[-1,:] = glacier0013['RACMO']['t']\n",
    "\n",
    "# NOTE: All times are the same for the TF time series for each glacier so we just set the times equal to the glacier0013 times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72195ce2-808b-4d82-b941-9bad720a11ef",
   "metadata": {},
   "source": [
    "## Load the parameters for the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81d0626-b522-4d19-8fa4-414c4bfd7bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ens_dict.pickle', 'rb') as f:\n",
    "    ens_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae404da5-1d7c-469c-97eb-59968169a043",
   "metadata": {},
   "source": [
    "## Loop through ensemble members and launch ISSM on the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-florence",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for trial_name, parameters in ens_data.items():\n",
    "    print('Launching ' + trial_name)\n",
    "    \n",
    "    # We set the transient parameters\n",
    "    md.transient.ismovingfront=1\n",
    "    md.transient.isthermal=0\n",
    "    md.transient.isstressbalance=1\n",
    "    md.transient.ismasstransport=1\n",
    "    md.transient.isgroundingline=1\n",
    "    md.groundingline.migration = 'SubelementMigration'\n",
    "\n",
    "    # We set the ocean conditions\n",
    "    md.frontalforcings.basin_id = basins_elements\n",
    "    md.frontalforcings.num_basins = 4\n",
    "\n",
    "    # We set the calving model\n",
    "    from calvingvonmises import calvingvonmises\n",
    "    md.calving = calvingvonmises()\n",
    "\n",
    "    # Set the requested outputs\n",
    "    md.stressbalance.requested_outputs=['default']\n",
    "    md.transient.requested_outputs=['default','IceVolumeAboveFloatation','BasalforcingsGroundediceMeltingRate','CalvingMeltingrate']\n",
    "\n",
    "    # SMCE cluster\n",
    "    from eis_nasa_smce import eis_nasa_smce\n",
    "    md.cluster = eis_nasa_smce()\n",
    "    md.cluster.name = 'pcluster.sealevel.eis.smce.nasa.gov'\n",
    "    md.cluster.partition = 'sealevel-c5n18xl-demand'\n",
    "    md.cluster.login = 'mpascual'\n",
    "    md.cluster.idfile = '~/.ssh/id_rsa'\n",
    "    md.cluster.executionpath = '/efs/mpascual/issm_execution_cluster'\n",
    "    md.cluster.cpuspernode = 14\n",
    "\n",
    "    md.settings.waitonlock = 0\n",
    "\n",
    "    # Go solve\n",
    "    md.miscellaneous.name = region + '_' + trial_name\n",
    "    md.verbose.solution=1\n",
    "    from solve import solve\n",
    "    md = solve(md, 'sb')\n",
    "\n",
    "    # Save this model \n",
    "    export_netCDF(md, '/efs/mpascual/GrIS_Outlet_Glacier_Seasonal_dhdt/Models/' + \\\n",
    "                  region + '_' + '_hindcast_EN4_RACMO_' + trial_name + '_sent2cluster.nc')\n",
    "    \n",
    "    print('')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c654e8-70e8-414f-8597-c25b451a285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = loadmodel(\"/efs/mpascual/GrIS_Outlet_Glacier_Seasonal_dhdt/Models/SAtoES__hindcast_EN4_RACMO_Trial0_sent2cluster.nc\")\n",
    "md = loadresultsfromcluster(md)\n",
    "#load md cluster results check sb fric coeff field\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "plotmodel(md, 'data', md.results.StressbalanceSolution.Vel[:,0], \\\n",
    "          'mask', md.mask.ice_levelset<0, 'colormap', 'jet', 'caxis', [0,1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global setup of the base model\n",
    "\n",
    "###################################################\n",
    "## 1) Load the _param model + common parameters  ##\n",
    "###################################################\n",
    "md = loadmodel('/efs/GrIS_Outlet_Glacier_Seasonal_dhdt/Models/SAtoES_Param.nc')\n",
    "\n",
    "#Setup\n",
    "region = 'SAtoES'\n",
    "start_year  = 1985.\n",
    "\n",
    "# Mesh sizing\n",
    "triangleresolution = 1000;\n",
    "hmin = 300;\n",
    "hmax = 10000;\n",
    "\n",
    "# Mesh\n",
    "md = model()\n",
    "md = triangle(md,'./Exp/' +region+ '.exp',triangleresolution) # set up mesh\n",
    "\n",
    "md = bamg(md,'hmin',hmin,'hmax',hmax,'field',vel,'err',2,'hmaxVertices',hmaxVertices);\n",
    "\n",
    "\n",
    "###################################\n",
    "## 2) for loop for each ensemble ##\n",
    "###################################\n",
    "import pickle\n",
    "with open('ens_dict.pickle', 'rb') as f:\n",
    "    ens_data = pickle.load(f)\n",
    "    \n",
    "for trial_name, parameters in ens_data.items():\n",
    "    print('Launching ' + trial_name)\n",
    "    \n",
    "    ####################################################\n",
    "    ## set friction coefficient and rheology with LHS ##\n",
    "    ####################################################\n",
    "    #set sliding law \n",
    "    md.friction.p = LHS value #(round to nearest whole number?)\n",
    "    \n",
    "    #set ice rheology\n",
    "    from cuffey import cuffey \n",
    "    #Vary Celsius range with LHS\n",
    "    temperature = -10 + (-10*LHS value) #(-15 = cold, -1 = warm)\n",
    "    # convert celsius to kelvin\n",
    "    temperature = temperature + 273.15 \n",
    "    #Calculate rigidity\n",
    "    rigidity = cuffey(temperature)\n",
    "    #Set rigidity calculation to rheology\n",
    "    md.materials.rheology_B = rigidity\n",
    "    \n",
    "    ####################\n",
    "    ## run inversion ##\n",
    "    ####################\n",
    "    md.inversion.iscontrol = 1 \n",
    "    from solve import solve\n",
    "    md = solve(md, 'sb')\n",
    "    \n",
    "    # Save this model \n",
    "    export_netCDF(md, '/efs/GrIS_Outlet_Glacier_Seasonal_dhdt/Models/inversion_models/' + \\\n",
    "                  region + '_' + '_hindcast_EN4_RACMO_inversion' + trial_name + '_sent2cluster.nc')\n",
    "    \n",
    "    ###############################################\n",
    "    ## extract friction coefficient and rheology ##\n",
    "    ###############################################\n",
    "    friction_coefficient = md.results.StressbalanceSolution.FrictionCoefficient\n",
    "    rheology_B = md.materials.rheology_B\n",
    "    #md_friction = None\n",
    "    \n",
    "    # Load the original model\n",
    "    #md = loadmodel(\"./Models/SAtoES_inversion.nc\")\n",
    "    md.friction.coefficient = friction_coefficient\n",
    "    md.materials.rheology_B = rheology_B\n",
    "\n",
    "    #################################################\n",
    "    ## Interpolate the 1985 DEM surface elevations ##\n",
    "    #################################################\n",
    "    z_1985dem = utilities.interp1985DEM(md.mesh.x, md.mesh.y)\n",
    "    # Select the points that will be used to create the linear relationship between the two surfaces\n",
    "    pos = (~np.isnan(z_1985dem - md.geometry.surface)) & (z_1985dem > 700) & (z_1985dem < 1000)\n",
    "    # Find the linear relationship\n",
    "    p = np.polyfit(md.geometry.surface[pos], z_1985dem[pos], 1)\n",
    "    z_polyval = np.polyval(p, md.geometry.surface[pos])\n",
    "    residuals = z_1985dem[pos] - z_polyval\n",
    "    # Shift the surface\n",
    "    surf_shifted = utilities.surface_shift(md, md.geometry.surface, z_1985dem)\n",
    "    md.geometry.surface = surf_shifted\n",
    "    \n",
    "    # Find the points where bed < 0 and the new surface > 42 m\n",
    "    ice_levelset_original = copy.deepcopy(md.mask.ice_levelset)\n",
    "    pos = (md.geometry.bed < 0) & (md.geometry.surface > 42) & (md.mask.ice_levelset > 0) & (md.mesh.vertexonboundary == 0)\n",
    "\n",
    "    # Fill in these points with ice\n",
    "    md.mask.ice_levelset[pos] = -1\n",
    "    md.mask.ice_levelset = reinitializelevelset(md, md.mask.ice_levelset)\n",
    "\n",
    "    # Extrapolate friction coefficient\n",
    "    from scipy.interpolate import griddata\n",
    "    valid = (ice_levelset_original < 0) & (md.geometry.surface < 300)\n",
    "    extrap = (md.geometry.bed < 0) & (md.geometry.surface > 42) & (ice_levelset_original > 0) & (md.mesh.vertexonboundary == 0)\n",
    "    friction_coefficient_extrap = griddata((md.mesh.x[valid], md.mesh.y[valid]), \\\n",
    "                                            md.friction.coefficient[valid], \\\n",
    "                                           (md.mesh.x[extrap], md.mesh.y[extrap]), \\\n",
    "                                            method='nearest')\n",
    "    md.friction.coefficient[extrap] = friction_coefficient_extrap\n",
    "\n",
    "\n",
    "    md.levelset.spclevelset = np.nan * np.ones((md.mesh.numberofvertices))\n",
    "    pos = md.mesh.vertexonboundary == 1\n",
    "    md.levelset.spclevelset[pos] = md.mask.ice_levelset[pos]\n",
    "    md.levelset.migration_max = 1e10\n",
    "    \n",
    "    ####################\n",
    "    ## set relaxation ##\n",
    "    ####################\n",
    "    relaxation_years = 30 #try 5 years if 1 runs quickly\n",
    "    \n",
    "    # Special post-processing of inverted friction coefficient\n",
    "    filename = 'Exp/' + region + '_coeffront_after_inversion.exp'\n",
    "    if os.path.isfile(filename):\n",
    "        print('adjusting inverted friction coefficient at the glacier fronts')\n",
    "        pos = find(ContourToNodes(md.mesh.x, md.mesh.y, filename, 1))\n",
    "        md.friction.coefficient[pos] = 10\n",
    "        \n",
    "    md.initialization.pressure = np.zeros([md.mesh.numberofvertices,1])\n",
    "    md.initialization.temperature = 250*np.ones([md.mesh.numberofvertices,1]) #temperature is in kelvin\n",
    "        \n",
    "    # Set parameters\n",
    "    md.inversion.iscontrol=0;\n",
    "    md.timestepping.start_time = start_year;\n",
    "    md.timestepping.time_step  = .02;\n",
    "    md.timestepping.final_time = start_year + relaxation_years;\n",
    "    md.settings.output_frequency = (1/md.timestepping.time_step)/5; # 5/yr\n",
    "    \n",
    "    #############################\n",
    "    ## input seasonal forcings ##\n",
    "    #############################\n",
    "        \n",
    "    # defining thermal and sub. discharge at every ISSM mesh node \n",
    "    # load raster of basins\n",
    "    ds = gdal.Open('./Cheat_matfiles/tidewaterbasins_rignotid.mat_tidewaterbasins.tif', gdal.GA_ReadOnly)\n",
    "    rb = ds.GetRasterBand(1)\n",
    "    basins_array = rb.ReadAsArray()\n",
    "        \n",
    "    gt = ds.GetGeoTransform()\n",
    "    ulx, xres, xskew, uly, yskew, yres  = gt\n",
    "    lrx = ulx + (ds.RasterXSize * xres)\n",
    "    lry = uly + (ds.RasterYSize * yres)\n",
    "    x = np.arange(ulx, lrx,  xres)\n",
    "    y = np.arange(lry, uly, -yres)\n",
    "        \n",
    "    # interpolate basin to each mesh node \n",
    "    px = np.array( ((md.mesh.x - gt[0]) / gt[1]).astype(int) )\n",
    "    py = np.array( ((md.mesh.y - gt[3]) / gt[5]).astype(int) )\n",
    "    basins_mesh = basins_array[py.astype(int), px.astype(int)]\n",
    "        \n",
    "    # ISSM wants basins to be numbered from 1 to 4 with the basins that we don't care about numbered 0\n",
    "    basins_mesh[basins_mesh==13] = 1\n",
    "    basins_mesh[basins_mesh==52] = 2\n",
    "    basins_mesh[basins_mesh==53] = 3\n",
    "    basins_mesh[basins_mesh==90] = 4\n",
    "    basins_mesh[(basins_mesh<1) | (basins_mesh>4)] = 0\n",
    "\n",
    "    # find basin id for each element\n",
    "    basins_elements = basins_mesh[md.mesh.elements-1]\n",
    "    basins_elements = np.max(basins_elements, axis=1)\n",
    "        \n",
    "    # Assigning ocean thermal (EN4) and subglacial discharge (RACMO2.3p2) forcings\n",
    "    from scipy_io_utils import *\n",
    "\n",
    "    # Load historical forcing data\n",
    "    glacier_list = list()\n",
    "    m = loadmat('./Cheat_matfiles/glacier0013.mat')\n",
    "    glacier0013 = m['glacier0013']\n",
    "    m = loadmat('./Cheat_matfiles/glacier0052.mat')\n",
    "    glacier0052 = m['glacier0052']\n",
    "    m = loadmat('./Cheat_matfiles/glacier0053.mat')\n",
    "    glacier0053 = m['glacier0053']\n",
    "    m = loadmat('./Cheat_matfiles/glacier0090.mat')\n",
    "    glacier0090 = m['glacier0090']\n",
    "\n",
    "    # Thermal forcing\n",
    "    t = glacier0013['EN4']['t']\n",
    "    TF = glacier0013['EN4']['TF']\n",
    "\n",
    "    # Discharge\n",
    "    t = glacier0013['RACMO']['Q']\n",
    "    Q = glacier0013['RACMO']['Q']\n",
    "\n",
    "    from frontalforcingsrignot import frontalforcingsrignot\n",
    "    md.frontalforcings = frontalforcingsrignot()\n",
    "    valid = ~np.isnan(glacier0013['EN4']['TF'])\n",
    "    md.frontalforcings.thermalforcing = np.zeros( (md.mesh.numberofvertices+1, len(glacier0013['EN4']['TF'][valid])) )\n",
    "    md.frontalforcings.subglacial_discharge = np.zeros( (md.mesh.numberofvertices+1, len(glacier0013['RACMO']['Q'])) )\n",
    "        \n",
    "    # Assign forcings to correct node \n",
    "    # step 1: find which nodes belong to each basin using basin_mesh\n",
    "    get_indexes = lambda basins_mesh, xs: [i for (y, i) in zip(xs, range(len(xs))) if basins_mesh == y]\n",
    "    glacier13_nodes = get_indexes(1,basins_mesh)\n",
    "    glacier52_nodes = get_indexes(2,basins_mesh)\n",
    "    glacier53_nodes = get_indexes(3,basins_mesh)\n",
    "    glacier90_nodes = get_indexes(4,basins_mesh)\n",
    "\n",
    "    # NOTE: Denis combined steps 2 and 3: we select the rows and set to the TF time series\n",
    "    # step 2: select() rows from frontalforcings.thermal that correspond to step 1 nodes\n",
    "    md.frontalforcings.thermalforcing[glacier13_nodes,:] = glacier0013['EN4']['TF'][valid]\n",
    "    md.frontalforcings.thermalforcing[glacier52_nodes,:] = glacier0052['EN4']['TF'][valid]\n",
    "    md.frontalforcings.thermalforcing[glacier53_nodes,:] = glacier0053['EN4']['TF'][valid]\n",
    "    md.frontalforcings.thermalforcing[glacier90_nodes,:] = glacier0090['EN4']['TF'][valid]\n",
    "\n",
    "    # step 2: select() rows from frontalforcings.subglacial_discharge that correspond to step 1 nodes\n",
    "    md.frontalforcings.subglacial_discharge[glacier13_nodes,:] = glacier0013['RACMO']['Q'] * 86400\n",
    "    md.frontalforcings.subglacial_discharge[glacier52_nodes,:] = glacier0052['RACMO']['Q'] * 86400\n",
    "    md.frontalforcings.subglacial_discharge[glacier53_nodes,:] = glacier0053['RACMO']['Q'] * 86400\n",
    "    md.frontalforcings.subglacial_discharge[glacier90_nodes,:] = glacier0090['RACMO']['Q'] * 86400\n",
    "\n",
    "    # NOTE: And now, set the last row to the time\n",
    "    md.frontalforcings.thermalforcing[-1,:] = glacier0013['EN4']['t'][valid]\n",
    "    md.frontalforcings.subglacial_discharge[-1,:] = glacier0013['RACMO']['t']\n",
    "    \n",
    "    #####################\n",
    "    ## set Calving law ##\n",
    "    #####################\n",
    "    from calvingvonmises import calvingvonmises\n",
    "    md.calving = calvingvonmises()\n",
    "    md.calving.stress_threshold_groundedice = md.calving.stress_threshold_groundedice + (md.calving.stress_threshold_groundedice * LHS value)\n",
    "    \n",
    "    ###################################\n",
    "    ## set the transient parameters ##\n",
    "    ###################################\n",
    "    md.transient.ismovingfront=1\n",
    "    md.transient.isthermal=0\n",
    "    md.transient.issmb = 0\n",
    "    md.thermal.isenthalpy = 0\n",
    "    md.transient.isstressbalance=1\n",
    "    md.transient.ismasstransport=1\n",
    "    md.transient.isgroundingline=1\n",
    "    md.groundingline.migration = 'SubelementMigration'\n",
    "    \n",
    "    # We set the ocean conditions\n",
    "    md.frontalforcings.basin_id = basins_elements\n",
    "    md.frontalforcings.num_basins = 4\n",
    "    \n",
    "    # SMCE pCluster\n",
    "    from eis_nasa_smce import eis_nasa_smce\n",
    "    md.cluster = eis_nasa_smce()\n",
    "    md.cluster.name = 'pcluster.sealevel.eis.smce.nasa.gov'\n",
    "    md.cluster.partition = 'sealevel-c5n18xl-demand'\n",
    "    md.cluster.login = 'mpascual'\n",
    "    md.cluster.idfile = '~/.ssh/id_rsa'\n",
    "    md.cluster.executionpath = '/efs/mpascual/issm_execution_cluster'\n",
    "    md.cluster.cpuspernode = 36\n",
    "    \n",
    "    md.settings.waitonlock = 0\n",
    "    \n",
    "    # Go solve\n",
    "    md.miscellaneous.name = region + '_' + trial_name\n",
    "    md.verbose.solution=1\n",
    "    from solve import solve\n",
    "    md = solve(md, 'tr')\n",
    "\n",
    "    # Save this model \n",
    "    export_netCDF(md, '/efs/dfelikso/GrIS_Outlet_Glacier_Seasonal_dhdt/Models/transient_models/' + \\\n",
    "                  region + '_' + '_hindcast_EN4_RACMO_transient' + trial_name + '_sent2cluster.nc')\n",
    "    \n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
